# Implementation Plan: FFI-Level Replay Handling

## Overview

Move replay logic from language SDKs to the Rust FFI layer. This ensures consistent replay behavior across all language SDKs with a single implementation.

**Design Document:** [FFI-Level Replay Handling Design](../design/ffi-replay-handling.md)

---

## Current State Analysis

### Existing FFI Architecture

The current FFI layer (`ffi/src/`) provides:

- **CoreWorker** (`worker.rs`): Polls for activations, submits completions
- **WorkflowActivation** (`activation.rs`): Contains history events passed to SDK
- **FfiWorkflowCommand** (`command.rs`): Commands generated by SDK
- **FfiReplayEvent** (`types.rs`): Replay events from server

### Current Problem

Language SDKs receive raw history and must implement replay logic:

```
SDK receives: WorkflowActivation { history: Vec<FfiReplayEvent>, ... }
SDK must: Parse events, match commands, track sequences, validate determinism
Result: Each SDK duplicates complex replay logic
```

### Existing Replay Implementation

The Rust SDK (`sdk/src/workflow/context_impl.rs`) already implements sophisticated replay:

- Per-type sequence counters (`next_task_seq`, `next_promise_seq`, etc.)
- Pre-filtered event lists (`task_events`, `promise_events`, etc.)
- Determinism validation with detailed error messages
- Terminal event matching by ID (taskExecutionId, timerId)

**Goal:** Expose this replay logic via FFI so language SDKs don't need to reimplement it.

---

## Architecture Changes

### From: SDK-Managed Replay

```
┌─────────────────────────────────┐
│ Kotlin SDK                      │
│  - Receives raw history         │
│  - Implements replay matching   │
│  - Generates all commands       │
│  - Tracks sequences             │
└────────────┬────────────────────┘
             │ commands (including duplicates during replay)
┌────────────▼────────────────────┐
│ FFI Layer                       │
│  - Passes through commands      │
│  - No replay awareness          │
└─────────────────────────────────┘
```

### To: FFI-Managed Replay

```
┌─────────────────────────────────┐
│ Kotlin SDK                      │
│  - Calls context methods        │
│  - Receives resolved/pending    │
│  - Thin wrapper, no replay logic│
└────────────┬────────────────────┘
             │ context method calls
┌────────────▼────────────────────┐
│ FFI Layer (FfiWorkflowContext)  │
│  - Stores replay events         │
│  - Matches commands to events   │
│  - Returns cached results       │
│  - Only generates NEW commands  │
└─────────────────────────────────┘
```

---

## Phase 1: Create FfiWorkflowContext

### 1.1 Add Context Module

Create `ffi/src/context.rs` with the core replay-aware context.

**File:** `ffi/src/context.rs`

```rust
#[derive(uniffi::Object)]
pub struct FfiWorkflowContext {
    // Identifiers
    workflow_execution_id: Uuid,
    tenant_id: Uuid,

    // Replay state - pre-filtered event lists
    task_events: Vec<ReplayEvent>,
    promise_events: Vec<ReplayEvent>,
    timer_events: Vec<ReplayEvent>,
    child_workflow_events: Vec<ReplayEvent>,
    operation_events: Vec<ReplayEvent>,
    state_events: Vec<ReplayEvent>,

    // Per-type sequence counters
    next_task_seq: AtomicU32,
    next_promise_seq: AtomicU32,
    next_timer_seq: AtomicU32,
    next_child_workflow_seq: AtomicU32,
    next_operation_seq: AtomicU32,

    // Generated commands (only NEW ones)
    commands: Mutex<Vec<FfiWorkflowCommand>>,

    // Resolved values from replay events
    completed_tasks: HashMap<String, TaskResult>,
    resolved_promises: HashMap<String, PromiseResult>,
    fired_timers: HashSet<String>,
    completed_child_workflows: HashMap<String, ChildWorkflowResult>,

    // Deterministic generation
    current_time_ms: i64,
    uuid_counter: AtomicI64,
    random_seed: u128,

    // Workflow state
    state: RwLock<HashMap<String, Vec<u8>>>,

    // Cancellation
    cancellation_requested: AtomicBool,
}
```

**Key Design Decisions:**

1. **Pre-filter events at construction**: Filter all events by type into separate lists for O(1) lookup during replay
2. **Build result maps upfront**: Parse terminal events (TaskCompleted, PromiseResolved, etc.) into lookup maps
3. **Atomic sequence counters**: Allow concurrent calls from SDK while maintaining deterministic ordering
4. **Commands only for NEW operations**: Don't record commands that replay from history

### 1.2 Implement Construction

```rust
impl FfiWorkflowContext {
    pub fn new(
        workflow_execution_id: Uuid,
        tenant_id: Uuid,
        timestamp_ms: i64,
        random_seed: Vec<u8>,
        events: Vec<FfiReplayEvent>,
        state_entries: Vec<StateEntry>,
    ) -> Self {
        // Convert FFI events to internal format
        let replay_events = Self::parse_events(&events);

        // Pre-filter by event type
        let task_events = Self::filter_events(&replay_events, EventType::TaskScheduled);
        let promise_events = Self::filter_events(&replay_events, EventType::PromiseCreated);
        let timer_events = Self::filter_events(&replay_events, EventType::TimerStarted);
        // ... etc

        // Build terminal event lookup maps
        let completed_tasks = Self::build_task_results(&replay_events);
        let resolved_promises = Self::build_promise_results(&replay_events);
        let fired_timers = Self::build_fired_timers(&replay_events);
        let completed_child_workflows = Self::build_child_workflow_results(&replay_events);

        // Initialize state from state entries
        let state = state_entries.into_iter()
            .map(|e| (e.key, e.value))
            .collect();

        Self {
            workflow_execution_id,
            tenant_id,
            task_events,
            promise_events,
            // ... initialize all fields
        }
    }
}
```

### 1.3 Implement Result Types

**File:** `ffi/src/context.rs` (result enums)

```rust
#[derive(uniffi::Enum)]
pub enum FfiTaskResult {
    /// Task completed during replay - return cached result
    Completed { output: Vec<u8> },
    /// Task failed during replay - return cached error
    Failed { error: String, retryable: bool },
    /// Task is new - workflow should suspend
    Pending { task_execution_id: String },
}

#[derive(uniffi::Enum)]
pub enum FfiPromiseResult {
    /// Promise resolved during replay
    Resolved { value: Vec<u8> },
    /// Promise rejected during replay
    Rejected { error: String },
    /// Promise timed out during replay
    TimedOut,
    /// Promise is new - workflow should suspend
    Pending { promise_id: String },
}

#[derive(uniffi::Enum)]
pub enum FfiTimerResult {
    /// Timer fired during replay
    Fired,
    /// Timer is new - workflow should suspend
    Pending { timer_id: String },
}

#[derive(uniffi::Enum)]
pub enum FfiChildWorkflowResult {
    /// Child workflow completed during replay
    Completed { output: Vec<u8> },
    /// Child workflow failed during replay
    Failed { error: String },
    /// Child workflow is new - workflow should suspend
    Pending { child_execution_id: String },
}

#[derive(uniffi::Enum)]
pub enum FfiOperationResult {
    /// Operation completed during replay (cached side effect)
    Cached { value: Vec<u8> },
    /// Operation is new - execute and record
    Execute { operation_seq: u32 },
}
```

### 1.4 Implement Context Methods

Each method follows the pattern:
1. Increment per-type sequence counter
2. Check if sequence exists in pre-filtered events
3. If exists: validate determinism, return cached result
4. If not: generate command, return Pending

**schedule_task:**

```rust
#[uniffi::export]
impl FfiWorkflowContext {
    pub fn schedule_task(
        &self,
        task_type: String,
        input: Vec<u8>,
        queue: Option<String>,
        timeout_ms: Option<i64>,
    ) -> Result<FfiTaskResult, FfiError> {
        let task_seq = self.next_task_seq.fetch_add(1, Ordering::SeqCst) as usize;

        if task_seq < self.task_events.len() {
            // Replay: validate and return cached result
            let event = &self.task_events[task_seq];
            let event_task_type = event.get_string("taskType")?;

            if event_task_type != task_type {
                return Err(FfiError::DeterminismViolation {
                    msg: format!(
                        "Task type mismatch at Task({}): expected '{}', got '{}'",
                        task_seq, task_type, event_task_type
                    ),
                });
            }

            let task_execution_id = event.get_string("taskExecutionId")?;

            // Look up terminal event result
            if let Some(result) = self.completed_tasks.get(&task_execution_id) {
                return Ok(result.clone());
            }

            // Task scheduled but not yet completed - still pending
            Ok(FfiTaskResult::Pending { task_execution_id })
        } else {
            // New command: generate and return pending
            let task_execution_id = Uuid::new_v4().to_string();

            self.commands.lock().push(FfiWorkflowCommand::ScheduleTask {
                task_execution_id: task_execution_id.clone(),
                task_type,
                input,
                queue,
                timeout_ms,
            });

            Ok(FfiTaskResult::Pending { task_execution_id })
        }
    }
}
```

**create_promise:**

```rust
pub fn create_promise(
    &self,
    name: String,
    timeout_ms: Option<i64>,
) -> Result<FfiPromiseResult, FfiError> {
    let promise_seq = self.next_promise_seq.fetch_add(1, Ordering::SeqCst) as usize;

    if promise_seq < self.promise_events.len() {
        // Replay: validate name and return cached result
        let event = &self.promise_events[promise_seq];
        let event_name = event.get_string("promiseId")?;

        if event_name != name {
            return Err(FfiError::DeterminismViolation {
                msg: format!(
                    "Promise name mismatch at Promise({}): expected '{}', got '{}'",
                    promise_seq, name, event_name
                ),
            });
        }

        // Look up terminal result
        if let Some(result) = self.resolved_promises.get(&name) {
            return Ok(result.clone());
        }

        Ok(FfiPromiseResult::Pending { promise_id: name })
    } else {
        // New command
        self.commands.lock().push(FfiWorkflowCommand::CreatePromise {
            promise_id: name.clone(),
            timeout_ms,
        });

        Ok(FfiPromiseResult::Pending { promise_id: name })
    }
}
```

**start_timer:**

```rust
pub fn start_timer(
    &self,
    duration_ms: i64,
) -> Result<FfiTimerResult, FfiError> {
    let timer_seq = self.next_timer_seq.fetch_add(1, Ordering::SeqCst) as usize;
    let timer_id = format!("timer-{}", timer_seq);

    if timer_seq < self.timer_events.len() {
        // Replay: validate timer_id
        let event = &self.timer_events[timer_seq];
        let event_timer_id = event.get_string("timerId")?;

        if event_timer_id != timer_id {
            return Err(FfiError::DeterminismViolation {
                msg: format!(
                    "Timer ID mismatch at Timer({}): expected '{}', got '{}'",
                    timer_seq, timer_id, event_timer_id
                ),
            });
        }

        // Check if timer fired
        if self.fired_timers.contains(&timer_id) {
            return Ok(FfiTimerResult::Fired);
        }

        Ok(FfiTimerResult::Pending { timer_id })
    } else {
        // New command
        self.commands.lock().push(FfiWorkflowCommand::StartTimer {
            timer_id: timer_id.clone(),
            duration_ms,
        });

        Ok(FfiTimerResult::Pending { timer_id })
    }
}
```

### 1.5 Implement Deterministic APIs

```rust
pub fn current_time_millis(&self) -> i64 {
    self.current_time_ms
}

pub fn random_uuid(&self) -> String {
    let counter = self.uuid_counter.fetch_add(1, Ordering::SeqCst);
    // Generate deterministic UUID from seed + counter
    let bytes = Self::derive_uuid_bytes(self.random_seed, counter);
    Uuid::from_bytes(bytes).to_string()
}

pub fn random(&self) -> f64 {
    // Use xorshift64 with seed for deterministic random
    // Same algorithm as sdk/src/workflow/context_impl.rs
}
```

### 1.6 Implement State Management

```rust
pub fn set_state(&self, key: String, value: Vec<u8>) -> Result<(), FfiError> {
    let state_seq = self.next_state_seq.fetch_add(1, Ordering::SeqCst) as usize;

    if state_seq < self.state_events.len() {
        // Validate key matches during replay
        let event = &self.state_events[state_seq];
        let event_key = event.get_string("key")?;

        if event_key != key {
            return Err(FfiError::DeterminismViolation {
                msg: format!(
                    "State key mismatch at State({}): expected '{}', got '{}'",
                    state_seq, key, event_key
                ),
            });
        }
    } else {
        // New command
        self.commands.lock().push(FfiWorkflowCommand::SetState {
            key: key.clone(),
            value: value.clone(),
        });
    }

    // Always update local state
    self.state.write().insert(key, value);
    Ok(())
}

pub fn get_state(&self, key: String) -> Option<Vec<u8>> {
    self.state.read().get(&key).cloned()
}

pub fn clear_state(&self, key: String) {
    self.state.write().remove(&key);
    self.commands.lock().push(FfiWorkflowCommand::ClearState { key });
}
```

### 1.7 Implement Command Extraction

```rust
pub fn take_commands(&self) -> Vec<FfiWorkflowCommand> {
    std::mem::take(&mut *self.commands.lock())
}

pub fn is_cancellation_requested(&self) -> bool {
    self.cancellation_requested.load(Ordering::SeqCst)
}
```

---

## Phase 2: Update CoreWorker

### 2.1 Create Context in poll_workflow_activation

Modify `CoreWorker::poll_workflow_activation()` to create `FfiWorkflowContext` with parsed events.

**File:** `ffi/src/worker.rs`

```rust
pub fn poll_workflow_activation(&self) -> Result<Option<WorkflowActivation>, FfiError> {
    // ... existing polling logic ...

    match result {
        Some(workflow_info) => {
            // Get events from server
            let events = self.get_workflow_events(workflow_info.id)?;
            let state = self.get_workflow_state(workflow_info.id)?;

            // Create replay-aware context
            let context = Arc::new(FfiWorkflowContext::new(
                workflow_info.id,
                Uuid::parse_str(&self.config.tenant_id).unwrap_or(Uuid::nil()),
                workflow_info.workflow_task_time_millis,
                workflow_info.random_seed,
                events.clone(),
                state.clone(),
            ));

            // Check for pending jobs (tasks completed, promises resolved, etc.)
            let jobs = self.build_activation_jobs(&workflow_info, &events);

            Ok(Some(WorkflowActivation {
                context,
                workflow_kind: workflow_info.kind,
                input: serde_json::to_vec(&workflow_info.input).unwrap_or_default(),
                jobs,
            }))
        }
        None => Ok(None),
    }
}
```

### 2.2 Replace WorkflowActivation Type

**File:** `ffi/src/activation.rs`

Replace the existing `WorkflowActivation` with context-based version:

```rust
/// Workflow activation with attached context for replay handling.
#[derive(uniffi::Record)]
pub struct WorkflowActivation {
    /// The replay-aware workflow context.
    pub context: Arc<FfiWorkflowContext>,

    /// The workflow kind/type.
    pub workflow_kind: String,

    /// Serialized workflow input as JSON bytes.
    pub input: Vec<u8>,

    /// Jobs to process (signals, queries, etc. that don't use context methods).
    pub jobs: Vec<WorkflowActivationJob>,
}
```

**Removed fields** (now in `FfiWorkflowContext`):
- `run_id` - context has `workflow_execution_id`
- `workflow_execution_id` - in context
- `timestamp_ms` - in context as `current_time_ms`
- `is_replaying` - context determines this from events
- `random_seed` - in context
- `history` - parsed into context event lists
- `state` - parsed into context state map

### 2.3 Update complete_workflow_activation

```rust
pub fn complete_workflow_activation(
    &self,
    context: &FfiWorkflowContext,
    status: WorkflowCompletionStatus,
) -> Result<(), FfiError> {
    // Extract commands from context
    let commands = context.take_commands();

    // Convert to proto and submit
    let proto_commands = commands.iter()
        .enumerate()
        .map(|(i, cmd)| cmd.to_proto_command(i as i32 + 1))
        .collect();

    match status {
        WorkflowCompletionStatus::Completed { output } => {
            self.submit_complete(context.workflow_execution_id, output, proto_commands)?;
        }
        WorkflowCompletionStatus::Suspended => {
            self.submit_suspend(context.workflow_execution_id, proto_commands)?;
        }
        WorkflowCompletionStatus::Failed { error } => {
            self.submit_fail(context.workflow_execution_id, error, proto_commands)?;
        }
    }

    Ok(())
}
```

### 2.4 Add WorkflowCompletionStatus

**File:** `ffi/src/activation.rs`

```rust
#[derive(uniffi::Enum)]
pub enum WorkflowCompletionStatus {
    /// Workflow completed successfully with output.
    Completed { output: Vec<u8> },

    /// Workflow suspended waiting for external events.
    Suspended,

    /// Workflow failed with error.
    Failed { error: String },
}
```

---

## Phase 3: Update lib.rs Exports

### 3.1 Export New Types

**File:** `ffi/src/lib.rs`

```rust
mod context;

pub use context::{
    FfiWorkflowContext,
    FfiTaskResult,
    FfiPromiseResult,
    FfiTimerResult,
    FfiChildWorkflowResult,
    FfiOperationResult,
};

pub use activation::{
    WorkflowActivation,       // Updated type with context
    WorkflowCompletionStatus, // New enum
    WorkflowActivationJob,    // Existing
    TaskActivation,           // Existing
    TaskCompletion,           // Existing
};
```

---

## Phase 4: Error Handling

### 4.1 Add Determinism Violation Error

**File:** `ffi/src/error.rs`

```rust
#[derive(Debug, Clone, uniffi::Error)]
pub enum FfiError {
    // ... existing variants ...

    /// Determinism violation detected during replay.
    #[error("Determinism violation: {msg}")]
    DeterminismViolation { msg: String },

    /// Event parsing error during replay.
    #[error("Event parsing error: {msg}")]
    EventParseError { msg: String },
}
```

---

## Phase 5: Testing

### 5.1 Unit Tests for FfiWorkflowContext

**File:** `ffi/src/context.rs` (tests module)

**Test categories:**

1. **Construction tests:**
   - `test_context_filters_events_by_type`
   - `test_context_builds_task_result_map`
   - `test_context_builds_promise_result_map`
   - `test_context_initializes_state_from_entries`

2. **Replay matching tests:**
   - `test_schedule_task_returns_completed_during_replay`
   - `test_schedule_task_returns_pending_for_new`
   - `test_schedule_task_validates_task_type`
   - `test_create_promise_returns_resolved_during_replay`
   - `test_create_promise_validates_name`
   - `test_start_timer_returns_fired_during_replay`
   - `test_start_timer_validates_timer_id`

3. **Determinism violation tests:**
   - `test_task_type_mismatch_raises_violation`
   - `test_promise_name_mismatch_raises_violation`
   - `test_timer_id_mismatch_raises_violation`
   - `test_child_workflow_name_mismatch_raises_violation`

4. **Command generation tests:**
   - `test_take_commands_returns_only_new_commands`
   - `test_replayed_operations_generate_no_commands`
   - `test_mixed_replay_and_new_commands`

5. **Deterministic API tests:**
   - `test_current_time_millis_returns_fixed_time`
   - `test_random_uuid_is_deterministic`
   - `test_random_is_deterministic`

### 5.2 Integration Tests

**File:** `ffi/tests/context_integration.rs`

- `test_full_workflow_replay_scenario`
- `test_partial_replay_with_new_commands`
- `test_context_with_real_server_events`

---

## Phase 6: Documentation

### 6.1 Update ffi/README.md

Document the new context-based API for language SDK implementors.

### 6.2 Add Code Comments

Document the replay algorithm and determinism requirements.

---

## TODO List

### Phase 1: Create FfiWorkflowContext ✅
- [x] Create `ffi/src/context.rs` module
- [x] Implement `FfiWorkflowContext` struct with all fields
- [x] Implement event parsing and filtering in `new()`
- [x] Implement terminal event result maps (`completed_tasks`, `resolved_promises`, etc.)
- [x] Implement `FfiTaskResult` enum
- [x] Implement `FfiPromiseResult` enum
- [x] Implement `FfiTimerResult` enum
- [x] Implement `FfiChildWorkflowResult` enum
- [x] Implement `FfiOperationResult` enum
- [x] Implement `schedule_task()` with replay handling
- [x] Implement `create_promise()` with replay handling
- [x] Implement `start_timer()` with replay handling
- [x] Implement `schedule_child_workflow()` with replay handling
- [x] Implement `run_operation()` for side effects
- [x] Implement `current_time_millis()`
- [x] Implement `random_uuid()` with deterministic generation
- [x] Implement `random()` with deterministic generation
- [x] Implement `set_state()` with replay validation
- [x] Implement `get_state()`
- [x] Implement `clear_state()`
- [x] Implement `take_commands()`
- [x] Implement `is_cancellation_requested()`
- [x] Add helper methods for event parsing

### Phase 2: Update CoreWorker ✅
- [x] Replace `WorkflowActivation` struct with context-based version in `activation.rs`
- [x] Add `WorkflowCompletionStatus` enum to `activation.rs`
- [x] Modify `poll_workflow_activation()` to return new `WorkflowActivation`
- [x] Add helper method to build activation jobs from events
- [x] Update `complete_workflow_activation()` to accept context and status
- [x] Update submission logic to extract commands from context
- [x] Remove `WorkflowActivationCompletion` type (commands now in context)

### Phase 3: Update Exports ✅
- [x] Add `mod context;` to `lib.rs`
- [x] Export all new types from `lib.rs`
- [x] Run `cargo build -p flovyn-ffi` to verify compilation
- [x] Verify uniffi generates correct bindings

### Phase 4: Error Handling ✅
- [x] Add `DeterminismViolation` variant to `FfiError`
- [x] Add `EventParseError` variant to `FfiError`
- [x] Ensure all context methods return proper errors

### Phase 5: Testing ✅
- [x] Add unit tests for context construction
- [x] Add unit tests for replay matching
- [x] Add unit tests for determinism violations
- [x] Add unit tests for command generation
- [x] Add unit tests for deterministic APIs
- [x] Add integration tests with mock events
- [x] Verify all tests pass: `cargo test -p flovyn-ffi`

### Phase 6: Documentation & Cleanup ✅
- [x] Document FfiWorkflowContext API
- [x] Add inline documentation for replay algorithm
- [x] Update CLAUDE.md if needed
- [x] Run clippy: `cargo clippy -p flovyn-ffi -- -D warnings`
- [x] Run fmt: `cargo fmt --all`

---

## Verification Checklist ✅

After implementation:

- [x] `cargo build --workspace` succeeds
- [x] `cargo test -p flovyn-ffi` passes (24 tests)
- [x] `cargo clippy --workspace --all-targets -- -D warnings` passes
- [x] `cargo fmt --all -- --check` passes
- [x] UniFFI bindings generate successfully
- [x] Context methods return correct results during replay
- [x] No duplicate commands generated during replay
- [x] Determinism violations detected with clear messages

---

## Phase 7: Kotlin SDK Changes

Based on exploration of `/Users/manhha/Developer/manhha/flovyn/sdk-kotlin`, the following changes are needed.

### 7.1 Current Kotlin Architecture

**Key Files:**
- `core/src/main/kotlin/ai/flovyn/sdk/workflow/WorkflowContext.kt` - Interface
- `core/src/main/kotlin/ai/flovyn/sdk/workflow/WorkflowContextImpl.kt` - Implementation
- `core/src/main/kotlin/ai/flovyn/sdk/worker/WorkflowWorker.kt` - Worker loop
- `core/src/main/kotlin/ai/flovyn/core/CoreBridge.kt` - FFI bridge wrapper

**Current Implementation Issues:**
1. `WorkflowContextImpl` maintains `mutableListOf<FfiWorkflowCommand>()` and generates commands on every call
2. `activation.history: List<FfiReplayEvent>` is provided but **NOT used** for validation
3. Each operation (`schedule()`, `sleep()`, `promise()`) generates a command and throws `WorkflowSuspendedException`
4. No mechanism to return cached results during replay
5. Jobs like `ResolveTask`, `FireTimer` are defined but not processed to resume workflows

### 7.2 Update WorkflowContextImpl

**File:** `sdk-kotlin/core/src/main/kotlin/ai/flovyn/sdk/workflow/WorkflowContextImpl.kt`

Replace command generation with FFI context calls:

```kotlin
class WorkflowContextImpl(
    private val ffiContext: FfiWorkflowContext,  // NEW: FFI context
    private val serializer: JsonSerializer,
    // Remove: commands: MutableList<FfiWorkflowCommand>
    // Remove: timestampMs, randomSeed (now in FFI context)
) : WorkflowContext {

    // BEFORE: Generated command and threw exception
    // AFTER: Call FFI, handle result
    override suspend fun <I : Any, O : Any> schedule(
        taskType: String,
        input: I,
        outputClass: KClass<O>,
        options: TaskOptions
    ): O {
        val inputBytes = serializer.serialize(input)

        return when (val result = ffiContext.scheduleTask(
            taskType = taskType,
            input = inputBytes,
            queue = options.queue,
            timeoutMs = options.timeout?.toMillis()
        )) {
            is FfiTaskResult.Completed -> {
                serializer.deserialize(result.output, outputClass)
            }
            is FfiTaskResult.Failed -> {
                throw TaskFailedException(result.error, result.retryable)
            }
            is FfiTaskResult.Pending -> {
                throw WorkflowSuspendedException("Waiting for task: ${result.taskExecutionId}")
            }
        }
    }

    override suspend fun sleep(duration: Duration) {
        when (val result = ffiContext.startTimer(duration.toMillis())) {
            is FfiTimerResult.Fired -> {
                // Timer already fired during replay - continue execution
            }
            is FfiTimerResult.Pending -> {
                throw WorkflowSuspendedException("Waiting for timer: ${result.timerId}")
            }
        }
    }

    override suspend fun <T : Any> promise(
        name: String,
        timeout: Duration?,
        valueClass: KClass<T>
    ): DurablePromise<T> {
        return when (val result = ffiContext.createPromise(name, timeout?.toMillis())) {
            is FfiPromiseResult.Resolved -> {
                ResolvedDurablePromise(serializer.deserialize(result.value, valueClass))
            }
            is FfiPromiseResult.Rejected -> {
                RejectedDurablePromise(result.error)
            }
            is FfiPromiseResult.TimedOut -> {
                TimedOutDurablePromise()
            }
            is FfiPromiseResult.Pending -> {
                throw WorkflowSuspendedException("Waiting for promise: ${result.promiseId}")
            }
        }
    }

    override suspend fun <I : Any, O : Any> scheduleWorkflow(
        name: String,
        kind: String?,
        input: I,
        taskQueue: String?,
        prioritySeconds: Int?
    ): O {
        val inputBytes = serializer.serialize(input)

        return when (val result = ffiContext.scheduleChildWorkflow(
            name = name,
            kind = kind,
            input = inputBytes,
            taskQueue = taskQueue,
            prioritySeconds = prioritySeconds
        )) {
            is FfiChildWorkflowResult.Completed -> {
                serializer.deserialize(result.output, outputClass)
            }
            is FfiChildWorkflowResult.Failed -> {
                throw ChildWorkflowFailedException(result.error)
            }
            is FfiChildWorkflowResult.Pending -> {
                throw WorkflowSuspendedException("Waiting for child: ${result.childExecutionId}")
            }
        }
    }

    override suspend fun <T : Any> run(name: String, block: suspend () -> T): T {
        return when (val result = ffiContext.runOperation(name)) {
            is FfiOperationResult.Cached -> {
                serializer.deserialize(result.value, outputClass)
            }
            is FfiOperationResult.Execute -> {
                // Execute the block and record result
                val value = block()
                ffiContext.recordOperationResult(name, serializer.serialize(value))
                value
            }
        }
    }

    // Deterministic APIs - delegate to FFI
    override fun currentTimeMillis(): Long = ffiContext.currentTimeMillis()
    override fun randomUUID(): UUID = UUID.fromString(ffiContext.randomUuid())
    override fun random(): Random = FfiBasedRandom(ffiContext)

    // State management - delegate to FFI
    override suspend fun <T : Any> get(key: String, valueClass: KClass<T>): T? {
        return ffiContext.getState(key)?.let { serializer.deserialize(it, valueClass) }
    }

    override suspend fun <T : Any> set(key: String, value: T) {
        ffiContext.setState(key, serializer.serialize(value))
    }

    override suspend fun clear(key: String) {
        ffiContext.clearState(key)
    }

    // Cancellation - delegate to FFI
    override fun isCancellationRequested(): Boolean = ffiContext.isCancellationRequested()

    // Remove: getCommands() - no longer needed, commands live in FFI context
}
```

### 7.3 Update WorkflowWorker

**File:** `sdk-kotlin/core/src/main/kotlin/ai/flovyn/sdk/worker/WorkflowWorker.kt`

```kotlin
class WorkflowWorker(
    private val coreBridge: CoreBridge,
    private val registry: WorkflowRegistry,
    private val hook: WorkflowHook?,
    private val serializer: JsonSerializer
) {
    suspend fun run() {
        while (!coreBridge.isShutdownRequested()) {
            val activation = coreBridge.pollWorkflowActivation() ?: continue
            processActivation(activation)
        }
    }

    private suspend fun processActivation(activation: WorkflowActivation) {
        val ffiContext = activation.context
        val workflow = registry.get(activation.workflowKind)

        // Create Kotlin context wrapping FFI context
        val context = WorkflowContextImpl(ffiContext, serializer)

        // Check cancellation job
        if (activation.jobs.any { it is WorkflowActivationJob.CancelWorkflow }) {
            ffiContext.requestCancellation()
        }

        try {
            // Execute workflow
            val input = serializer.deserialize(activation.input, workflow.inputClass)
            val result = workflow.execute(context, input)

            // Complete - FFI context has accumulated commands
            coreBridge.completeWorkflowActivation(
                ffiContext,
                WorkflowCompletionStatus.Completed(serializer.serialize(result))
            )
        } catch (e: WorkflowSuspendedException) {
            // Suspend - FFI context has accumulated commands
            coreBridge.completeWorkflowActivation(
                ffiContext,
                WorkflowCompletionStatus.Suspended
            )
        } catch (e: WorkflowCancelledException) {
            coreBridge.completeWorkflowActivation(
                ffiContext,
                WorkflowCompletionStatus.Cancelled(e.message ?: "Cancelled")
            )
        } catch (e: DeterminismViolationException) {
            // Handle determinism errors from FFI
            coreBridge.completeWorkflowActivation(
                ffiContext,
                WorkflowCompletionStatus.Failed("Determinism violation: ${e.message}")
            )
        } catch (e: Exception) {
            coreBridge.completeWorkflowActivation(
                ffiContext,
                WorkflowCompletionStatus.Failed(e.message ?: "Unknown error")
            )
        }
    }
}
```

### 7.4 Update CoreBridge

**File:** `sdk-kotlin/core/src/main/kotlin/ai/flovyn/core/CoreBridge.kt`

```kotlin
class CoreBridge private constructor(private val worker: CoreWorker) {

    fun pollWorkflowActivation(): WorkflowActivation? {
        return worker.pollWorkflowActivation()
    }

    fun completeWorkflowActivation(
        context: FfiWorkflowContext,
        status: WorkflowCompletionStatus
    ) {
        worker.completeWorkflowActivation(context, status)
    }

    // Existing methods for tasks remain unchanged
    fun pollTaskActivation(): TaskActivation? = worker.pollTaskActivation()
    fun completeTask(completion: TaskCompletion) = worker.completeTask(completion)
    fun initiateShutdown() = worker.initiateShutdown()
    fun isShutdownRequested(): Boolean = worker.isShutdownRequested()
}
```

### 7.5 Add Exception Types

**File:** `sdk-kotlin/core/src/main/kotlin/ai/flovyn/sdk/workflow/Exceptions.kt`

```kotlin
// NEW: Map FFI DeterminismViolation to Kotlin exception
class DeterminismViolationException(message: String) : RuntimeException(message)

// Existing - ensure these handle FFI error cases
class TaskFailedException(message: String, val retryable: Boolean) : RuntimeException(message)
class ChildWorkflowFailedException(message: String) : RuntimeException(message)
class PromiseRejectedException(message: String) : RuntimeException(message)
class PromiseTimeoutException(promiseId: String) : RuntimeException("Promise timed out: $promiseId")
```

### 7.6 Remove Unused Code

After migration, remove:
- `WorkflowContextImpl.commands` list
- `WorkflowContextImpl.getCommands()` method
- `WorkflowContextImpl.timestampMs` and `randomSeed` fields
- `SeededRandom` class (now handled by FFI)
- Any local replay/history validation code

---

## Phase 8: Integration Testing

### 8.1 Cross-SDK Replay Test

Create a test that:
1. Starts workflow from Kotlin SDK
2. Workflow schedules task, creates promise, starts timer
3. Workflow suspends
4. Task completes, promise resolves, timer fires
5. Workflow resumes (replay)
6. Verify: no duplicate commands, correct results returned

**File:** `sdk-kotlin/core/src/test/kotlin/ai/flovyn/sdk/ReplayIntegrationTest.kt`

### 8.2 Determinism Violation Test

1. Start workflow that schedules task "type-A"
2. Complete task
3. Change workflow code to schedule task "type-B"
4. Resume workflow
5. Verify: `DeterminismViolationException` thrown

---

## TODO List Updates

### Phase 7: Kotlin SDK Changes ✅
- [x] Update `WorkflowContextImpl` to accept `FfiWorkflowContext`
- [x] Replace `schedule()` command generation with FFI call
- [x] Replace `sleep()` command generation with FFI call
- [x] Replace `promise()` command generation with FFI call
- [x] Replace `scheduleWorkflow()` command generation with FFI call
- [x] Replace `run()` command generation with FFI call
- [x] Update `currentTimeMillis()` to delegate to FFI
- [x] Update `randomUUID()` to delegate to FFI
- [x] Update `random()` to use FFI-backed Random (`FfiBasedRandom`)
- [x] Update state methods (`get`, `set`, `clear`) to delegate to FFI
- [x] Update `isCancellationRequested()` to delegate to FFI
- [x] Remove `commands` list from `WorkflowContextImpl`
- [x] Remove `getCommands()` method
- [x] Update `WorkflowWorker` to use new FFI API
- [x] Add `DeterminismViolationException` handling
- [x] Update `CoreBridge` to use new FFI methods
- [x] Remove old `CoreBridge` methods
- [x] Remove `SeededRandom` class
- [x] Update existing tests
- [ ] Add replay integration tests (future work)
- [ ] Add determinism violation tests (future work)

### Phase 8: Integration Testing ✅
- [ ] Create cross-SDK replay E2E test (future work)
- [ ] Create determinism violation E2E test (future work)
- [x] Verify Kotlin SDK works with real server (E2E tests pass)
- [x] Run full test suite (all 10 workflow E2E tests pass)

---

## Risks and Mitigations

| Risk | Mitigation |
|------|------------|
| Breaking change to FFI API | Acceptable - this is a development SDK, coordinate changes across Rust and Kotlin |
| Complex event parsing | Reuse existing event parsing from sdk/src/workflow/ |
| Thread safety issues | Use atomics for counters, mutex for commands |
| Performance regression | Pre-filter events at construction, O(1) lookups |
| Debugging difficulty | Include detailed error messages with sequence info |
| Kotlin SDK compatibility | Update Kotlin SDK in same PR as FFI changes |
