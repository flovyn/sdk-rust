# Design: Task Streaming

**Status**: Draft
**Created**: 2025-12-21
**Author**: Claude Code
**Related**: [grpc-client-apis-enhancement.md](./grpc-client-apis-enhancement.md)

## Overview

This document describes the design for real-time task streaming in the Rust SDK. Task streaming enables tasks to emit ephemeral events (tokens, progress, data, errors) that are delivered to connected clients in real-time. This is essential for LLM token streaming, progress monitoring, and real-time data pipelines.

### Goals

1. **LLM Integration**: Stream tokens as they're generated by language models
2. **Progress Visibility**: Real-time progress updates for long-running tasks
3. **Data Pipelines**: Stream intermediate results during data processing
4. **Error Notification**: Immediate error feedback to monitoring systems

### Non-Goals

1. Event persistence (streams are ephemeral)
2. Guaranteed delivery (best-effort, fire-and-forget)
3. Event replay (no history, live only)
4. Backpressure handling (server buffers, may drop on overflow)

---

## Architecture

### Data Flow

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                            STREAMING ARCHITECTURE                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────┐     gRPC           ┌─────────────┐      SSE        ┌─────┐│
│  │  Task       │  StreamTaskData    │   Server    │  /api/.../stream│ Web ││
│  │  (Rust SDK) │ ──────────────────►│  (Kotlin)   │ ◄───────────────│ App ││
│  └─────────────┘     (unary)        └──────┬──────┘    (HTTP GET)   └─────┘│
│                                            │                                │
│                                            ▼                                │
│                                     ┌─────────────┐                         │
│                                     │  Pub/Sub    │                         │
│                                     │ (NATS/Mem)  │                         │
│                                     └─────────────┘                         │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Protocol Layers

| Layer | Protocol | Direction | Purpose |
|-------|----------|-----------|---------|
| Task → Server | gRPC (unary) | Push | Send stream events |
| Server Internal | NATS/Memory | Pub/Sub | Route to subscribers |
| Server → Client | SSE (HTTP) | Push | Deliver to browsers/apps |

---

## Stream Event Types

### Enum Definition

```rust
/// Type of stream event
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum StreamEventType {
    /// LLM token or text chunk
    Token,
    /// Progress update (0.0-1.0)
    Progress,
    /// Arbitrary structured data
    Data,
    /// Error notification
    Error,
}
```

### Event Variants

```rust
/// Stream event emitted by tasks during execution.
///
/// Events are ephemeral (not persisted) and delivered to connected clients
/// in real-time via Server-Sent Events (SSE).
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", rename_all = "lowercase")]
pub enum StreamEvent {
    /// LLM token or text chunk.
    ///
    /// Use for streaming text generation from language models.
    ///
    /// # Example
    /// ```rust
    /// for token in llm.generate_stream(prompt) {
    ///     ctx.stream(StreamEvent::Token { text: token }).await?;
    /// }
    /// ```
    Token {
        /// The token or text chunk
        text: String,
    },

    /// Progress update with optional details.
    ///
    /// Use for long-running tasks to show completion percentage.
    ///
    /// # Example
    /// ```rust
    /// for (i, item) in items.iter().enumerate() {
    ///     let progress = (i + 1) as f64 / items.len() as f64;
    ///     ctx.stream(StreamEvent::Progress {
    ///         progress,
    ///         details: Some(format!("Processing {}", item.name)),
    ///     }).await?;
    ///     process(item).await?;
    /// }
    /// ```
    Progress {
        /// Progress value (0.0 to 1.0)
        #[serde(serialize_with = "serialize_progress")]
        progress: f64,
        /// Optional progress details
        #[serde(skip_serializing_if = "Option::is_none")]
        details: Option<String>,
    },

    /// Arbitrary structured data.
    ///
    /// Use for streaming intermediate results or custom events.
    ///
    /// # Example
    /// ```rust
    /// ctx.stream(StreamEvent::Data {
    ///     data: json!({
    ///         "chunk_id": 42,
    ///         "rows_processed": 1000,
    ///         "sample": first_row,
    ///     }),
    /// }).await?;
    /// ```
    Data {
        /// Data payload (JSON-serializable)
        data: Value,
    },

    /// Error notification.
    ///
    /// Use to notify clients of recoverable errors during execution.
    /// For fatal errors, let the task fail normally.
    ///
    /// # Example
    /// ```rust
    /// match fetch_data().await {
    ///     Ok(data) => process(data),
    ///     Err(e) if e.is_retryable() => {
    ///         ctx.stream(StreamEvent::Error {
    ///             message: format!("Retrying: {}", e),
    ///             code: Some("RETRY".into()),
    ///         }).await?;
    ///         retry().await?
    ///     }
    ///     Err(e) => return Err(e.into()),
    /// }
    /// ```
    Error {
        /// Error message
        message: String,
        /// Optional error code
        #[serde(skip_serializing_if = "Option::is_none")]
        code: Option<String>,
    },
}

// Ensure progress is clamped to 0.0-1.0
fn serialize_progress<S>(value: &f64, serializer: S) -> Result<S::Ok, S::Error>
where
    S: serde::Serializer,
{
    serializer.serialize_f64(value.clamp(0.0, 1.0))
}
```

---

## TaskContext API

### Current TaskContext (Internal)

```rust
/// Context provided to task execution
pub struct TaskContext {
    task_execution_id: String,
    workflow_execution_id: String,
    input: Value,
    // ... other fields
}
```

### Extended TaskContext

```rust
impl TaskContext {
    // === Existing Methods ===

    /// Report progress (persisted, for server tracking)
    pub async fn report_progress(&self, progress: f64, details: Option<&str>) -> Result<(), TaskError>;

    /// Send heartbeat
    pub async fn heartbeat(&self) -> Result<(), TaskError>;

    /// Log a message
    pub async fn log(&self, level: LogLevel, message: &str) -> Result<(), TaskError>;

    // === New Streaming Methods ===

    /// Stream an event to connected clients.
    ///
    /// Events are ephemeral (not persisted) and delivered via SSE.
    /// This method is fire-and-forget; delivery failures are logged but not returned.
    ///
    /// # Example
    ///
    /// ```rust
    /// // Stream LLM tokens
    /// for token in llm.stream_completion(prompt).await? {
    ///     ctx.stream(StreamEvent::Token { text: token }).await?;
    /// }
    ///
    /// // Stream progress
    /// ctx.stream(StreamEvent::Progress {
    ///     progress: 0.5,
    ///     details: Some("Halfway done".into()),
    /// }).await?;
    /// ```
    pub async fn stream(&self, event: StreamEvent) -> Result<(), TaskError>;

    /// Stream a token (convenience method).
    ///
    /// Equivalent to `stream(StreamEvent::Token { text })`.
    pub async fn stream_token(&self, text: impl Into<String>) -> Result<(), TaskError> {
        self.stream(StreamEvent::Token { text: text.into() }).await
    }

    /// Stream progress (convenience method).
    ///
    /// Equivalent to `stream(StreamEvent::Progress { progress, details })`.
    pub async fn stream_progress(
        &self,
        progress: f64,
        details: Option<impl Into<String>>,
    ) -> Result<(), TaskError> {
        self.stream(StreamEvent::Progress {
            progress,
            details: details.map(Into::into),
        }).await
    }

    /// Stream data (convenience method).
    ///
    /// Equivalent to `stream(StreamEvent::Data { data })`.
    pub async fn stream_data(&self, data: impl Serialize) -> Result<(), TaskError> {
        self.stream(StreamEvent::Data {
            data: serde_json::to_value(data)?,
        }).await
    }

    /// Stream an error (convenience method).
    ///
    /// Equivalent to `stream(StreamEvent::Error { message, code })`.
    pub async fn stream_error(
        &self,
        message: impl Into<String>,
        code: Option<impl Into<String>>,
    ) -> Result<(), TaskError> {
        self.stream(StreamEvent::Error {
            message: message.into(),
            code: code.map(Into::into),
        }).await
    }
}
```

---

## gRPC Implementation

### Current Protocol

```protobuf
service TaskExecution {
  // Stream task data (tokens, progress, etc.)
  rpc StreamTaskData(StreamTaskDataRequest) returns (StreamTaskDataResponse);
}

message StreamTaskDataRequest {
  string task_execution_id = 1;
  string workflow_execution_id = 2;
  int32 sequence = 3;
  StreamEventType type = 4;
  string payload = 5;        // JSON-encoded event data
  int64 timestamp_ms = 6;
}

message StreamTaskDataResponse {
  bool acknowledged = 1;
}

enum StreamEventType {
  STREAM_EVENT_TYPE_UNSPECIFIED = 0;
  TOKEN = 1;
  PROGRESS = 2;
  DATA = 3;
  ERROR = 4;
}
```

### Rust Client Implementation

```rust
/// Internal client for streaming task events
pub(crate) struct TaskStreamClient {
    stub: TaskExecutionClient<Channel>,
    sequence: AtomicU32,
}

impl TaskStreamClient {
    pub fn new(channel: Channel, worker_token: &str) -> Self {
        let interceptor = WorkerTokenInterceptor::new(worker_token);
        let stub = TaskExecutionClient::with_interceptor(channel, interceptor);
        Self {
            stub,
            sequence: AtomicU32::new(0),
        }
    }

    pub async fn stream_event(
        &self,
        task_execution_id: &str,
        workflow_execution_id: &str,
        event: &StreamEvent,
    ) -> Result<(), TaskError> {
        let (event_type, payload) = match event {
            StreamEvent::Token { text } => (
                StreamEventType::Token,
                serde_json::json!({ "type": "token", "text": text }),
            ),
            StreamEvent::Progress { progress, details } => (
                StreamEventType::Progress,
                serde_json::json!({
                    "type": "progress",
                    "progress": progress,
                    "details": details,
                }),
            ),
            StreamEvent::Data { data } => (
                StreamEventType::Data,
                serde_json::json!({ "type": "data", "data": data }),
            ),
            StreamEvent::Error { message, code } => (
                StreamEventType::Error,
                serde_json::json!({
                    "type": "error",
                    "message": message,
                    "code": code,
                }),
            ),
        };

        let request = StreamTaskDataRequest {
            task_execution_id: task_execution_id.to_string(),
            workflow_execution_id: workflow_execution_id.to_string(),
            sequence: self.sequence.fetch_add(1, Ordering::SeqCst) as i32,
            r#type: event_type as i32,
            payload: payload.to_string(),
            timestamp_ms: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_millis() as i64,
        };

        let response = self.stub.clone().stream_task_data(request).await?;

        if !response.into_inner().acknowledged {
            debug!("Stream event not acknowledged");
        }

        Ok(())
    }
}
```

### Error Handling

Streaming uses fire-and-forget semantics with logging:

```rust
impl TaskContext {
    pub async fn stream(&self, event: StreamEvent) -> Result<(), TaskError> {
        match self.stream_client.stream_event(
            &self.task_execution_id,
            &self.workflow_execution_id,
            &event,
        ).await {
            Ok(_) => Ok(()),
            Err(e) => {
                // Log but don't fail the task
                warn!(
                    "Failed to stream event for task {}: {}",
                    self.task_execution_id, e
                );
                // Return Ok to avoid failing the task
                // Streaming is best-effort
                Ok(())
            }
        }
    }
}
```

---

## Client-Side Subscription (SDK)

While the primary consumption is via SSE in web clients, the Rust SDK should also provide a way to subscribe to streams programmatically.

### FlovynClient API

```rust
impl FlovynClient {
    /// Subscribe to stream events for a workflow.
    ///
    /// Returns a stream of events from all tasks in the workflow.
    /// Events are delivered via SSE from the server.
    ///
    /// # Example
    ///
    /// ```rust
    /// let mut stream = client.subscribe_workflow_stream(workflow_id).await?;
    ///
    /// while let Some(event) = stream.next().await {
    ///     match event? {
    ///         TaskStreamEvent { event: StreamEvent::Token { text }, .. } => {
    ///             print!("{}", text);
    ///         }
    ///         TaskStreamEvent { event: StreamEvent::Progress { progress, .. }, .. } => {
    ///             println!("\nProgress: {:.0}%", progress * 100.0);
    ///         }
    ///         _ => {}
    ///     }
    /// }
    /// ```
    pub async fn subscribe_workflow_stream(
        &self,
        workflow_execution_id: Uuid,
    ) -> Result<impl Stream<Item = Result<TaskStreamEvent, StreamError>>, ClientError>;

    /// Subscribe to stream events for a specific task.
    ///
    /// Filters the workflow stream to only include events from the specified task.
    pub async fn subscribe_task_stream(
        &self,
        workflow_execution_id: Uuid,
        task_execution_id: Uuid,
    ) -> Result<impl Stream<Item = Result<StreamEvent, StreamError>>, ClientError>;
}

/// Stream event with task context
#[derive(Debug, Clone)]
pub struct TaskStreamEvent {
    /// Task that emitted the event
    pub task_execution_id: Uuid,
    /// Workflow containing the task
    pub workflow_execution_id: Uuid,
    /// Event sequence number
    pub sequence: u32,
    /// The stream event
    pub event: StreamEvent,
    /// Timestamp when event was emitted
    pub timestamp: SystemTime,
}

#[derive(Debug, thiserror::Error)]
pub enum StreamError {
    #[error("Connection closed")]
    ConnectionClosed,

    #[error("Stream timeout")]
    Timeout,

    #[error("Parse error: {0}")]
    ParseError(String),

    #[error("HTTP error: {0}")]
    HttpError(#[from] reqwest::Error),
}
```

### SSE Client Implementation

```rust
use eventsource_stream::Eventsource;
use futures::StreamExt;

pub(crate) struct SseStreamClient {
    base_url: String,
    auth_token: String,
    tenant_slug: String,
    http_client: reqwest::Client,
}

impl SseStreamClient {
    pub async fn subscribe_workflow(
        &self,
        workflow_execution_id: Uuid,
    ) -> Result<impl Stream<Item = Result<TaskStreamEvent, StreamError>>, ClientError> {
        let url = format!(
            "{}/api/tenants/{}/stream/workflows/{}",
            self.base_url, self.tenant_slug, workflow_execution_id
        );

        let response = self.http_client
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.auth_token))
            .header("Accept", "text/event-stream")
            .send()
            .await?;

        let stream = response
            .bytes_stream()
            .eventsource()
            .map(|result| {
                result
                    .map_err(|e| StreamError::ParseError(e.to_string()))
                    .and_then(|event| {
                        parse_sse_event(&event)
                    })
            });

        Ok(stream)
    }
}

fn parse_sse_event(event: &eventsource_stream::Event) -> Result<TaskStreamEvent, StreamError> {
    let event_type = match event.event.as_str() {
        "token" => StreamEventType::Token,
        "progress" => StreamEventType::Progress,
        "data" => StreamEventType::Data,
        "error" => StreamEventType::Error,
        _ => return Err(StreamError::ParseError(format!("Unknown event type: {}", event.event))),
    };

    let payload: Value = serde_json::from_str(&event.data)
        .map_err(|e| StreamError::ParseError(e.to_string()))?;

    // Parse based on event type
    let stream_event = match event_type {
        StreamEventType::Token => StreamEvent::Token {
            text: payload["text"].as_str().unwrap_or_default().to_string(),
        },
        StreamEventType::Progress => StreamEvent::Progress {
            progress: payload["progress"].as_f64().unwrap_or(0.0),
            details: payload["details"].as_str().map(String::from),
        },
        StreamEventType::Data => StreamEvent::Data {
            data: payload["data"].clone(),
        },
        StreamEventType::Error => StreamEvent::Error {
            message: payload["message"].as_str().unwrap_or_default().to_string(),
            code: payload["code"].as_str().map(String::from),
        },
    };

    // Extract sequence from event ID
    let sequence = event.id
        .as_ref()
        .and_then(|id| id.parse::<u32>().ok())
        .unwrap_or(0);

    Ok(TaskStreamEvent {
        task_execution_id: Uuid::nil(), // TODO: Parse from consolidated stream
        workflow_execution_id: Uuid::nil(), // TODO: Parse from consolidated stream
        sequence,
        event: stream_event,
        timestamp: SystemTime::now(),
    })
}
```

---

## Configuration

### Builder Options

```rust
impl FlovynClientBuilder {
    /// Set the base URL for SSE streaming (default: same as gRPC server)
    pub fn streaming_url(self, url: impl Into<String>) -> Self;

    /// Set streaming connection timeout (default: 30 seconds)
    pub fn streaming_connect_timeout(self, timeout: Duration) -> Self;

    /// Set streaming read timeout (default: 5 minutes)
    pub fn streaming_read_timeout(self, timeout: Duration) -> Self;

    /// Enable or disable streaming (default: enabled)
    pub fn enable_streaming(self, enabled: bool) -> Self;
}
```

### Task Configuration

```rust
impl TaskDefinition for MyTask {
    // ... existing methods ...

    /// Whether this task uses streaming
    fn uses_streaming(&self) -> bool {
        false // Default: false
    }
}
```

---

## Examples

### Example 1: LLM Token Streaming

```rust
use flovyn_sdk::prelude::*;
use async_openai::{Client, types::CreateCompletionRequestArgs};

#[derive(Clone)]
struct LlmTask {
    openai: Client,
}

impl TaskDefinition for LlmTask {
    const KIND: &'static str = "llm-completion";
    type Input = LlmInput;
    type Output = LlmOutput;

    fn uses_streaming(&self) -> bool {
        true
    }

    async fn execute(&self, ctx: &TaskContext, input: LlmInput) -> Result<LlmOutput, TaskError> {
        ctx.stream_progress(0.0, Some("Starting LLM generation")).await?;

        let request = CreateCompletionRequestArgs::default()
            .model("gpt-4")
            .prompt(&input.prompt)
            .stream(true)
            .build()?;

        let mut stream = self.openai.completions().create_stream(request).await?;
        let mut full_text = String::new();
        let mut token_count = 0;

        while let Some(response) = stream.next().await {
            let response = response?;
            for choice in response.choices {
                if let Some(text) = choice.text {
                    // Stream each token
                    ctx.stream_token(&text).await?;
                    full_text.push_str(&text);
                    token_count += 1;
                }
            }

            // Update progress periodically
            if token_count % 10 == 0 {
                ctx.stream_progress(
                    0.5, // Approximate, real progress unknown
                    Some(format!("Generated {} tokens", token_count)),
                ).await?;
            }
        }

        ctx.stream_progress(1.0, Some("Generation complete")).await?;

        Ok(LlmOutput {
            text: full_text,
            token_count,
        })
    }
}

#[derive(Deserialize)]
struct LlmInput {
    prompt: String,
}

#[derive(Serialize)]
struct LlmOutput {
    text: String,
    token_count: usize,
}
```

### Example 2: Data Pipeline with Progress

```rust
#[derive(Clone)]
struct DataProcessingTask;

impl TaskDefinition for DataProcessingTask {
    const KIND: &'static str = "data-processing";
    type Input = DataInput;
    type Output = DataOutput;

    fn uses_streaming(&self) -> bool {
        true
    }

    async fn execute(&self, ctx: &TaskContext, input: DataInput) -> Result<DataOutput, TaskError> {
        let total = input.records.len();
        let mut processed = 0;
        let mut results = Vec::with_capacity(total);

        ctx.stream_progress(0.0, Some(format!("Processing {} records", total))).await?;

        for (i, record) in input.records.into_iter().enumerate() {
            // Check for cancellation
            ctx.check_cancellation()?;

            match process_record(&record).await {
                Ok(result) => {
                    results.push(result);
                    processed += 1;

                    // Stream intermediate result every 100 records
                    if processed % 100 == 0 {
                        ctx.stream_data(json!({
                            "processed": processed,
                            "total": total,
                            "last_id": record.id,
                        })).await?;
                    }
                }
                Err(e) => {
                    // Stream error but continue processing
                    ctx.stream_error(
                        format!("Failed to process record {}: {}", record.id, e),
                        Some("RECORD_ERROR"),
                    ).await?;
                }
            }

            // Update progress
            let progress = (i + 1) as f64 / total as f64;
            ctx.stream_progress(progress, None).await?;
        }

        ctx.stream_progress(1.0, Some(format!("Completed {} records", processed))).await?;

        Ok(DataOutput {
            processed,
            failed: total - processed,
            results,
        })
    }
}
```

### Example 3: Client Subscribing to Stream

```rust
use flovyn_sdk::prelude::*;
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = FlovynClient::builder()
        .server_address("localhost", 9090)
        .tenant_id(tenant_id)
        .worker_token(token)
        .streaming_url("http://localhost:8080") // REST API for SSE
        .build()
        .await?;

    // Start a workflow that uses streaming tasks
    let workflow_id = client
        .start_workflow("llm-workflow", json!({ "prompt": "Tell me a story" }))
        .await?;

    println!("Started workflow: {}", workflow_id);

    // Subscribe to stream
    let mut stream = client.subscribe_workflow_stream(workflow_id).await?;

    // Print tokens as they arrive
    while let Some(event) = stream.next().await {
        match event? {
            TaskStreamEvent { event: StreamEvent::Token { text }, .. } => {
                print!("{}", text);
                std::io::stdout().flush()?;
            }
            TaskStreamEvent { event: StreamEvent::Progress { progress, details }, .. } => {
                println!("\n[Progress: {:.0}%] {:?}", progress * 100.0, details);
            }
            TaskStreamEvent { event: StreamEvent::Error { message, code }, .. } => {
                eprintln!("\n[Error {:?}]: {}", code, message);
            }
            _ => {}
        }
    }

    println!("\nStream completed");

    Ok(())
}
```

### Example 4: JavaScript Client (Reference)

```javascript
// Web client using SSE
const eventSource = new EventSource(
  `/api/tenants/${tenantSlug}/stream/workflows/${workflowId}`,
  { withCredentials: true }
);

// Accumulate tokens
let fullText = '';

eventSource.addEventListener('token', (event) => {
  const data = JSON.parse(event.data);
  fullText += data.text;
  document.getElementById('output').textContent = fullText;
});

eventSource.addEventListener('progress', (event) => {
  const data = JSON.parse(event.data);
  document.getElementById('progress').style.width = `${data.progress * 100}%`;
  if (data.details) {
    document.getElementById('status').textContent = data.details;
  }
});

eventSource.addEventListener('error', (event) => {
  const data = JSON.parse(event.data);
  console.error(`Error [${data.code}]: ${data.message}`);
});

eventSource.onerror = () => {
  console.log('Stream closed');
  eventSource.close();
};
```

---

## E2E Tests

### Test: Task Streams Tokens

```rust
#[tokio::test]
async fn test_task_streams_tokens() {
    let server = start_test_server().await;
    let client = create_test_client(&server).await;

    let _worker = client.start().await.unwrap();

    // Start workflow with streaming task
    let workflow_id = client
        .start_workflow("streaming-task-workflow", json!({}))
        .await
        .unwrap();

    // Subscribe to stream
    let mut stream = client.subscribe_workflow_stream(workflow_id).await.unwrap();

    let mut tokens = Vec::new();
    let timeout = tokio::time::timeout(Duration::from_secs(30), async {
        while let Some(event) = stream.next().await {
            if let Ok(TaskStreamEvent { event: StreamEvent::Token { text }, .. }) = event {
                tokens.push(text);
            }
        }
    });

    let _ = timeout.await;

    // Verify tokens received
    assert!(!tokens.is_empty(), "Should receive tokens");
    let full_text: String = tokens.join("");
    assert!(!full_text.is_empty(), "Tokens should form text");
}
```

### Test: Task Streams Progress

```rust
#[tokio::test]
async fn test_task_streams_progress() {
    let server = start_test_server().await;
    let client = create_test_client(&server).await;

    let _worker = client.start().await.unwrap();

    let workflow_id = client
        .start_workflow("progress-task-workflow", json!({}))
        .await
        .unwrap();

    let mut stream = client.subscribe_workflow_stream(workflow_id).await.unwrap();

    let mut progress_values = Vec::new();
    let timeout = tokio::time::timeout(Duration::from_secs(30), async {
        while let Some(event) = stream.next().await {
            if let Ok(TaskStreamEvent { event: StreamEvent::Progress { progress, .. }, .. }) = event {
                progress_values.push(progress);
            }
        }
    });

    let _ = timeout.await;

    // Verify progress updates
    assert!(!progress_values.is_empty(), "Should receive progress updates");
    assert!(progress_values.iter().any(|&p| p >= 1.0), "Should reach 100%");

    // Progress should be monotonically increasing
    for window in progress_values.windows(2) {
        assert!(window[1] >= window[0], "Progress should increase");
    }
}
```

### Test: Stream Error Events

```rust
#[tokio::test]
async fn test_task_streams_errors() {
    let server = start_test_server().await;
    let client = create_test_client(&server).await;

    let _worker = client.start().await.unwrap();

    // Start workflow that streams recoverable errors
    let workflow_id = client
        .start_workflow("error-streaming-workflow", json!({}))
        .await
        .unwrap();

    let mut stream = client.subscribe_workflow_stream(workflow_id).await.unwrap();

    let mut errors = Vec::new();
    let timeout = tokio::time::timeout(Duration::from_secs(30), async {
        while let Some(event) = stream.next().await {
            if let Ok(TaskStreamEvent { event: StreamEvent::Error { message, code }, .. }) = event {
                errors.push((message, code));
            }
        }
    });

    let _ = timeout.await;

    // Verify error events received
    assert!(!errors.is_empty(), "Should receive error events");
    assert!(errors.iter().any(|(_, code)| code.as_deref() == Some("RETRY")));
}
```

### Test: Stream Connection Timeout

```rust
#[tokio::test]
async fn test_stream_connection_timeout() {
    let client = FlovynClient::builder()
        .server_address("localhost", 9999) // Wrong port
        .tenant_id(test_tenant_id())
        .worker_token(test_token())
        .streaming_connect_timeout(Duration::from_millis(100))
        .build()
        .await
        .unwrap();

    let result = client.subscribe_workflow_stream(Uuid::new_v4()).await;

    assert!(matches!(result, Err(ClientError::ConnectionError(_))));
}
```

---

## Performance Considerations

### Batching

For high-frequency streaming (e.g., many small tokens), consider client-side batching:

```rust
impl TaskContext {
    /// Stream multiple events in a batch.
    ///
    /// More efficient than individual `stream()` calls for high-frequency events.
    pub async fn stream_batch(&self, events: Vec<StreamEvent>) -> Result<(), TaskError>;
}
```

### Rate Limiting

The server implements rate limiting on streaming endpoints:

- Default: 100 events/second per workflow
- Burst: 200 events allowed
- Excess events are dropped (not queued)

### Memory Considerations

- Events are not buffered client-side
- Stream processing should be non-blocking
- Large data events should be avoided (prefer chunked streaming)

---

## Alternatives Considered

### 1. gRPC Streaming (Server → Client)

Use bidirectional gRPC streaming instead of SSE.

**Pros**:
- Single protocol (gRPC everywhere)
- Binary efficiency

**Cons**:
- Browser support requires grpc-web proxy
- More complex connection management
- SSE is simpler for web clients

**Decision**: SSE for client-side, gRPC for task-side (hybrid approach)

### 2. WebSocket

Use WebSocket instead of SSE.

**Pros**:
- Bidirectional communication
- Binary support

**Cons**:
- More complex protocol
- SSE is sufficient for our use case (server → client only)
- Spring SSE is well-supported

**Decision**: SSE is simpler and sufficient

### 3. Persistent Event Storage

Store stream events for replay.

**Pros**:
- Historical access
- Debugging

**Cons**:
- Storage costs (especially for LLM tokens)
- Complexity
- Not needed for primary use cases

**Decision**: Events are ephemeral by design; use workflow events for audit trail

---

## Open Questions

1. **Sequence Gaps**: How should clients handle sequence gaps? Ignore or request resync?
   - Proposed: Ignore gaps (best-effort streaming)

2. **Large Events**: Should we limit event payload size?
   - Proposed: 1MB limit, recommend chunking for larger data

3. **Compression**: Should SSE events be compressed?
   - Proposed: Yes, enable gzip on server (transparent to clients)

4. **Authentication**: How to pass auth token for SSE in browsers?
   - Proposed: Cookie-based auth for browser, Bearer token for SDK

---

## Implementation Phases

### Phase 1: Task-Side Streaming
- Add `stream()` method to `TaskContext`
- Implement gRPC `StreamTaskData` client
- Add convenience methods (`stream_token`, etc.)

### Phase 2: SDK Client Subscription
- Implement SSE client
- Add `subscribe_workflow_stream()` to `FlovynClient`
- Add stream filtering and parsing

### Phase 3: Configuration
- Add streaming configuration to builder
- Add `uses_streaming()` to `TaskDefinition`
- Document configuration options

### Phase 4: Testing
- E2E tests for streaming scenarios
- Performance benchmarks
- Browser integration tests

---

## References

- [Kotlin SDK StreamEvent](file:///Users/manhha/Developer/manhha/leanapp/flovyn/sdk/kotlin/src/main/kotlin/ai/flovyn/sdk/kotlin/task/StreamEvent.kt)
- [Server StreamingController](file:///Users/manhha/Developer/manhha/leanapp/flovyn/server/app/src/main/kotlin/ai/flovyn/streaming/StreamingController.kt)
- [gRPC Protocol](file:///Users/manhha/Developer/manhha/flovyn/sdk-rust/proto/flovyn.proto)
- [MDN: Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
